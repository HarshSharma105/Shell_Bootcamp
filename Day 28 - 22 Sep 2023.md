- Operations in RDD:
	- Transformations
	- Actions
- df.rdd.getNumPartitions() => gives number of partitions of a file.
- Repartitioning => df.repartition(200)
- Spark UI => spark.
- SparkSQL
- if-else equivalent in pyspark => when-otherwise
- udf_func = udf(function_name, returnDataType()). => returnDataType: (StringType, IntegerType, FloatType)
- caching
- regexp_replace(column_name, old, new)
- df write modes: overwrite, append
- coalesce => join partitions while writing to create only given no. of files