## *Big Data Fundamentals*

### Big Data: (follows 4 V's)
- **Volume**: Scale of Data
- **Variety**: Forms of Data
- **Velocity**: Analysis of data flow
- **Veracity**: Uncertainty of Data

#### Batch and Stream Processing

**Batch Processing**: Data is processed in batches. Generally at the end after some fix time (like reports generated at the end)
`Recorded events` >==`read`==> `Periodic Query/Application` >==`write`==> `Database/HDFS` & `Report`

**Stream Processing**: Data is processed continuously (live reporting).
`Real-time events` >==`ingest`==> `Continuous Query/Application` >==`update`==> 

Big data needs to go through ETL jobs: Extract, Transform, Load.

Big Processed in Parallel or Distributive Processing.

Spark supports both Batch and Stream Processing.
Spark is popular and better than Hadoop (only supports Batch Processing).

### DWH (data warehouse)
(Stores structured data for optimized querying and reporting)
- save data as objects : tables, views
- Structured data
- Dimension Modelling (**a technique used in data warehousing to organize and structure data in a way that makes it easy to analyze and understand**. In a dimensional data model, data is organised into dimensions and facts.)
- Fixed Schema
- ACID Properties: Atomicity(The entire transaction takes place at once or doesn't happen at all), Consistency(The database must be consistent before and after the transaction), Isolation(Multiple transactions occur independently without interference), Durability(The changes of a successful transaction occurs even if the system failure occurs)

### Data Lake
(Accommodates structured and unstructured data, enabling exploration and versatility)
- Structured
- Unstructured
- Semi-structured
- Flexible Schema
- Don't follow ACID Properties
- Every data stored in data lake will have a metadata.

### Data Lakehouse
(Combines data warehouse and data lake features, supporting structured and unstructured data with schema enforcement and analytics capabilities)
- Just like data lake, but follows ACID properties also.

Activated Sandbox on microsoft learning for creating virtual machine.

### Cloud Computing Basics

**Types**: Public, Private, and Hybrid cloud

**Benefits**: High availability, scalability, global search, agility, disaster recovery, fault tolerance, elasticity, customer latency capability, predictive cost considerations, security.

**Cloud models**: CapEx and OpEx

**Capital Expenditure (CapEx)**: 
- the up-front spending of money on physical infrastructure.
- Costs from CapEx have a value that reduces over time.
- Ex: Buying a Car.

**Operational expenditure (OpEx)**:
- Used only when required.
- payment is immediately done (just like booking a uber).

**Consumption based model**:
- Better cost prediction

**Shared Responsibility Model**:
- On-Premises (private cloud)
- Infrastructure (as a service):
	- Compute
	- Networking
	- Storage
	- you manage => Data and access, applications, and Runtime, OS, VM
- Platform (as a service):
	- Compute
	- Networking
	- Storage
	- Runtime
	- OS
	- VM
	- you manage => Data and access, and applications
- Software (as a service):
	- Applications
	- others in platform as a service
	- you manage => data and access

**Serverless Computing:** Users don't have to worry about server maintenance, updates.
Azure Functions
Azure Logic Apps

### Azure Fundamentals:

- Region
- Region Pairs (for backup in case a region goes down): separated by atleast 300 miles. 
- Availability Zones: availability zones can have many data centers connected through fibre optic cables, and an Azure Region have many availability zones.

#### Azure Subscriptions: 
(Provides you with authenticated and authorised access to Azure accounts)
- Billing boundary
- Access boundary

#### Azure Resource Manager
(ARM provides a management layer that enables you to create, update and manage resources in Azure subscription)

##### Azure Resource Groups:
(container to manage and aggregate resources in a single unit)

